## Nombre del Postwork: Colección de Datos

### OBJETIVO 

- Identificar las diferentes maneras que hay de coleccionar datos y utilizar la más apropiada para responder a tus preguntas.

#### REQUISITOS 

- Haber elegido un problema que te parezca interesante.
- Haberte planteado una serie de preguntas que te parecen relevantes para tu problema.

#### DESARROLLO

Hemos llegado al paso #3 de nuestro proyecto de Ciencia de Datos: La Colección de Datos. Para poder responder a las preguntas que hemos planteado, es absolutamente necesario tener datos que podamos analizar. Estos datos pueden provenir de diversas fuentes. Esta es una lista no exhaustiva de lugares donde podría haber datos:

1. Una plataforma hecha específicamente para almacenar datasets, como Kaggle.
2. Una plataforma de investigación científica que tiene datasets disponibles para personas que quieran reproducir algún hallazgo.
3. Páginas web donde están los datos que necesitamos, pero que no ofrecen descarga de dichos datos.
4. APIs públicas o privadas donde podemos pedir datos de manera remota.
5. Bases de Datos a las que tenemos acceso (de nuestra empresa, institución educativa, etc.)
6. Sensores que están recabando datos de algún fenómeno y recabándolos en una base de datos.
7. Archivos .xlsx, .csv, .json, .tsv, etc, que nos han sido compartidos por alguien.
8. Google Forms.
9. Datos que hemos recabado manualmente en una encuesta.

Las fuentes de datos son numerosas **PERO** no siempre contienen los datos que nosotros necesitamos.

- Normalmente el primer paso es buscar si alguien ya ha recopilado los datos que necesitamos.
- Si nadie lo ha hecho, toca ver si es posible recabarlos de alguna página web que los tenga pero no en formato descargable. Esto es lo que se llama *Web Scraping*.
- Si tampoco existe esa información lo único que queda preguntarse es: "¿tengo una manera de recabar estos datos por mí mismo?".
- Si tampoco eso es posible, entonces lamento decirte que tal vez tengas que cambiar de problema, plantearte nuevas preguntas o buscar una perspectiva diferente de tu problema.

En este Postwork lo que vamos a hacer es buscar datos para nuestro problema. Vamos a empezar explorando algunas fuentes de datasets que ofrecen mucha variedad. Si no hay ningún dataset ahí que te sirva, podrías explorar con la experta la posiblidad de hacer Web Scraping para conseguirlo. Aunque este tema no está incluido en el módulo, puedes explorar estas fuentes e intentarlo si te sientes cómodo explorando ese tema por ti mismo:

- [Documentación de Selenium](https://www.selenium.dev/)
- [Intro a Selenium](https://medium.com/the-andela-way/introduction-to-web-scraping-using-selenium-7ec377a8cf72)
- [Tutorial de Web Scraping usando Selenium](https://towardsdatascience.com/web-scraping-using-selenium-python-8a60f4cf40ab)
- [Implementación de Web Scraping usando Selenium](https://github.com/joseramon-arias/scraper-whoscored)

Recuerda que este tema no está incluido en el módulo, así que tendrás que realizar gran parte de la exploración por ti mismo.

---

Vamos a buscar nuestro dataset, entonces. Éstas son algunas fuentes donde puedes encontrar datasets en grandes cantidades:

- [Kaggle](https://www.kaggle.com/)
- [FiveThirtyEight](https://data.fivethirtyeight.com/)
- [BuzzFeed News](https://github.com/BuzzFeedNews)
- [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)
- [UCL Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)
- [Academic Torrents](http://academictorrents.com/browse.php)
- [Quandl](https://www.quandl.com/search)

Busca estas fuentes para encontrar algo que te sea de utilidad. Si no encuentras lo que buscas, puedes preguntarle a la experta para ver si conoce otras fuentes.

Una vez que encuentres tu dataset, descárgalo y guárdalo en la carpeta [Datasets](../../Datasets/Readme.md) que está en la raíz del repositorio de este módulo. En caso de que encuentres una API que provea los datos que necesites, habla con la experta para que te ayude a descargar el conjunto de datos. El tema de APIs se explorará a más profundidad en una sesión posterior, pero por lo pronto la experta puede proveerte el código o el software necesario para descargar tus datos exitosamente.
